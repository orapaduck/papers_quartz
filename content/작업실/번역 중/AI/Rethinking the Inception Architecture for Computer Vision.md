---
Created: 2024-01-20
Last Modified: 2024-01-20
tags:
  - CV
DOI: "\rhttps://doi.org/10.48550/arXiv.1512.00567"
ì™„ë£Œ ì—¬ë¶€: false
---
```text-progress-bar
progress:: 1/8.5
fill:ğŸŸ©
transition:ğŸŸ¨
empty:â—»ï¸
prefix:[
suffix:]
length:10
```
## Abstract
&emsp;ì»¨ë³¼ë£¨ì…˜ ë„¤í¬ì›Œí¬ëŠ” ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ê³¼ì œì— ëŒ€í•œ state-of-the-art ì»´í“¨í„° ë¹„ì „ ì†”ë£¨ì…˜ì˜ í•µì‹¬ì…ë‹ˆë‹¤. 2014ë…„ë„ ë¶€í„° ë§¤ìš° ê¹Šì€ ì»¨ë³¼ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬ê°€ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒë‹¹í•œ ë°œì „ì„ ì·¨í•˜ë©° ì£¼ë¥¼ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤. <font color="#ff0000">ëª¨ë¸ì˜ í¬ê¸°ì™€ ê³„ì‚° ë¹„ìš©ì˜ ì¦ê°€ëŠ” ëŒ€ë¶€ë¶„ì˜ ê³¼ì œì—ì„œ ì¦‰ê°ì ì¸ í’ˆì§ˆ í–¥ìƒìœ¼ë¡œ ì´ì–´ì§€ëŠ” ê²½í–¥ì´ ìˆì§€ë§Œ (í›ˆë ¨ì„ ìœ„í•œ ë¼ë²¨ë§ ë°ì´í„°ê°€ ì¶©ë¶„íˆ ì£¼ì–´ì§€ëŠ” í•œì—ì„œ), ê³„ì‚° íš¨ìœ¨ì„±ê³¼ ì ì€ ë§¤ê°œë³€ìˆ˜ëŠ” ëª¨ë°”ì¼ ë¹„ì „ ë° ë¹…ë°ì´í„°ì™€ ê°™ì€ ë‹¤ì–‘í•œ í™œìš© ì‚¬ë¡€ì—ì„œ ì—¬ì „íˆ ì¤‘ìš”í•œ ìš”ì¸ì…ë‹ˆë‹¤. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios.</font> ì—¬ê¸°ì—ì„œ ìš°ë¦¬ëŠ” ì ì ˆíˆ ì¸ìˆ˜ë¶„í•´ëœ ì»¨ë³¼ë£¨ì…˜ê³¼ ê³µê²©ì ì¸ ì •ê·œí™”ë¥¼ í†µí•´ ì¶”ê°€ëœ ê³„ì‚°ì„ ìµœëŒ€í•œ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ë„¤íŠ¸ì›Œí¬ì˜ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ëŠ” ë°©ë²•ì„ íƒìƒ‰í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ILSVRC 2012 classification challenge validation setì„ í†µí•´ ìš°ë¦¬ì˜ ë°©ë²•ì„ ë²¤ì¹˜ë§ˆí‚¹í•˜ì˜€ê³ , ì´ëŠ” state-of-the-artì— ë¹„í•´ ìƒë‹¹í•œ ê°œì„ ì„ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤: ì¶”ë¡ ë‹¹ 50ì–µë²ˆì˜ ê³±ì…ˆ ë° ë§ì…ˆì— í•´ë‹¹í•˜ëŠ” ê³„ì‚° ë¹„ìš©ê³¼ 2500ë§Œê°œ ë¯¸ë§Œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ë‹¨ì¼ í”„ë ˆì„ í‰ê°€ì—ì„œ 21.2%ì˜ top-1 error ê·¸ë¦¬ê³  5.6%ì˜ top-5 errorë¥¼ ë‹¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤. 4ê°œì˜ ëª¨ë¸ì„ ì•™ìƒë¸”í•œ ë’¤ multi-crop evaluationì„ í•œ ê²°ê³¼ 3.5%ì˜ top-5 errorì™€ 17.3%ì˜ top-1 errorê°€ ë‚˜íƒ€ë‚¨ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.
## 1. Introduction
&emsp;2012ë…„ ImageNet competition [16]ì—ì„œ Krizhevsky et al [9] ì´ ì…ìƒí•œ ì´í›„, ê·¸ë“¤ì˜ ë„¤íŠ¸ì›Œí¬ì¸ "AlexNet"ì€ object detection [5], segmentation [12], human pose estimation [22], video classification [8], object tracking [23] ê·¸ë¦¬ê³  superresolution [3] ë“± ë‹¤ì–‘í•œ ì»´í“¨í„° ë¹„ì „ ê³¼ì œì— ì„±ê³µì ìœ¼ë¡œ ë„ì…ë˜ì–´ ì™”ìŠµë‹ˆë‹¤.

&emsp;ì´ëŸ¬í•œ ì„±ê³µì€ ë” ë‚˜ì€ ì„±ëŠ¥ì˜ CNNì„ ì°¾ëŠ” ë°ì— ì´ˆì ì„ ë‘” ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì´‰ì§„ì‹œì¼°ìŠµë‹ˆë‹¤. 2014ë…„ë¶€í„° ë” ê¹Šê³  ë„“ì€ ë„¤íŠ¸ì›Œí¬ë“¤ì„ í™œìš©í•¨ìœ¼ë¡œì¨ ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ì˜ ì„±ì´ í™•ì—°íˆ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤. VGGNet [18] ê³¼ GoogLeNet [20]ì€ 2014 ILSVRC [16] classifiacation challengeì—ì„œ ë¹„ìŠ·í•˜ê²Œ ë†’ì€ ì„±ëŠ¥ì„ ë‚´ì—ˆìŠµë‹ˆë‹¤. í•œ ê°€ì§€ í¥ë¯¸ë¡œìš´ ê´€ì¸¡ ê²°ê³¼ëŠ” classification ì„±ëŠ¥ì´ ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì—ì„œì˜ ìƒë‹¹í•œ í’ˆì§ˆ í–¥ìƒìœ¼ë¡œ ì´ì–´ì§„ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ê¹Šì€ ì»¨ë³¼ë£¨ì…˜ ì•„í‚¤í…ì²˜ì—ì„œì˜ êµ¬ì¡°ì  ê°œì„ ì´ ë†’ì€ í’ˆì§ˆì˜ í•™ìŠµëœ ì‹œê°ì  íŠ¹ì§•ì— ì ì  ë” ì˜ì¡´í•˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ë‹¤ë¥¸ ì»´í“¨í„° ë¹„ì „ ê³¼ì œì—ì„œì˜ ì„±ëŠ¥ì„ ê°œì„  ì‹œí‚¤ëŠ” ë°ì— í™œìš©ë  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë˜í•œ, AlexNetì´ ìˆ˜ì‘ì—…ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ solutionì— ì¤€í•˜ëŠ” ì„±ëŠ¥ì„ ë‚´ì§€ ëª»í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ê²½ìš°ì—ì„œ(e.g. proposal generation in detection[4]),ë„¤íŠ¸ì›Œí¬ í’ˆì§ˆì˜ ê°œì„ ì´ ìƒˆë¡œìš´ ì»¨ë³¼ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬ì˜ ì‘ìš© ë¶„ì•¼ë¥¼ íƒ„ìƒì‹œì¼°ìŠµë‹ˆë‹¤.

&emsp;VGGNet [18] ì´ êµ¬ì¡°ì  ë‹¨ìˆœì„±ì— ê°•ì ì„ ê°€ì§€ì§€ë§Œ, ì´ëŠ” ë†’ì€ ë¹„ìš©ì„ ì´ˆë˜í•©ë‹ˆë‹¤: ë„¤íŠ¸ì›Œí¬ë¥¼ í‰ê°€í•˜ëŠ” ë°ì— ë§ì€ ê³„ì‚°ì´ ìš”êµ¬ë©ë‹ˆë‹¤. ë°˜ë©´ì—, GoogLeNet [20] ì˜ inception ì•„í‚¤í…ì²˜ëŠ” ë©”ëª¨ë¦¬ì™€ ê³„ì‚° í•œë„ì— ëŒ€í•œ ì—„ê²©í•œ ì œí•œ ë‚´ì—ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, GoogLeNetì€ 500ë§Œê°œì˜ íŒŒë¼ë¯¸í„°ë§Œì„ ì‚¬ìš©í•˜ì˜€ìœ¼ë©° ì´ëŠ” 600ë§Œê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì˜€ë˜ AlexNetì— ë¹„í•´ 12ë°° ê°ì†Œí•œ ìˆ˜ì¹˜ì…ë‹ˆë‹¤. ê²Œë‹¤ê°€, VGGNetì€ AlexNet ë³´ë‹¤ ì•½ 3ë°° ë” ë§ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

&emsp;Inceptionì˜ ê³„ì‚° ë¹„ìš©ì€ VGGNetì´ë‚˜ ë” ë†’ì€ ì„±ëŠ¥ì˜ í›„ì† ëª¨ë¸ë“¤ ë³´ë‹¤ í›¨ì”¬ ë‚®ìŠµë‹ˆë‹¤ [6]. ì´ëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ í•©ë¦¬ì ì¸ ë¹„ìš©ìœ¼ë¡œ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ë¹…ë°ì´í„° ë¶„ì•¼ë‚˜ ëª¨ë°”ì¼ ë¹„ì „ê³¼ ê°™ì´ ë©”ëª¨ë¦¬ ë˜ëŠ” ê³„ì‚° ìš©ëŸ‰ì´ ë³¸ì§ˆì ìœ¼ë¡œ ì œí•œëœ í™˜ê²½ì—ì„œ Inception ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš© ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“¤ì–´ì™”ìŠµë‹ˆë‹¤.
## 2. General Design Principles
## 3. Factorizing Convolutions with Large Filter Size
## 3.1. Factorization into smaller convolutions
## 3.2. Spatial Factorization into Asymmetric Convolutions
## 4. Utility of Auxiliary Classifiers
## 5. Efficient Grid Size Reduction
## 6. Inception-v2

## References
[1] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mane,Â´ R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viegas, O. Vinyals, P. War- Â´ den, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org. 
[2] W. Chen, J. T. Wilson, S. Tyree, K. Q. Weinberger, and Y. Chen. Compressing neural networks with the hashing trick. In Proceedings of The 32nd International Conference on Machine Learning, 2015. 
[3] C. Dong, C. C. Loy, K. He, and X. Tang. Learning a deep convolutional network for image super-resolution. In Computer Visionâ€“ECCV 2014, pages 184â€“199. Springer, 2014. 
[4] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov. Scalable object detection using deep neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2155â€“2162. IEEE, 2014. 
[5] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014. 
[6] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. arXiv preprint arXiv:1502.01852, 2015. 
[7] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of The 32nd International Conference on Machine Learning, pages 448â€“456, 2015. 
[8] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and L. Fei-Fei. Large-scale video classification with convolutional neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 1725â€“1732. IEEE, 2014. 
[9] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097â€“1105, 2012. 
[10] A. Lavin. Fast algorithms for convolutional neural networks. arXiv preprint arXiv:1509.09308, 2015. 
[11] C.-Y. Lee, S. Xie, P. Gallagher, Z. Zhang, and Z. Tu. Deeplysupervised nets. arXiv preprint arXiv:1409.5185, 2014. 
[12] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3431â€“3440, 2015. 
[13] Y. Movshovitz-Attias, Q. Yu, M. C. Stumpe, V. Shet, S. Arnoud, and L. Yatziv. Ontological supervision for fine grained classification of street view storefronts. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1693â€“1702, 2015. 
[14] R. Pascanu, T. Mikolov, and Y. Bengio. On the difficulty of training recurrent neural networks. arXiv preprint arXiv:1211.5063, 2012. 
[15] D. C. Psichogios and L. H. Ungar. Svd-net: an algorithm that automatically selects network structure. IEEE transactions on neural networks/a publication of the IEEE Neural Networks Council, 5(3):513â€“515, 1993. 
[16] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. 2014. 
[17] F. Schroff, D. Kalenichenko, and J. Philbin. Facenet: A unified embedding for face recognition and clustering. arXiv preprint arXiv:1503.03832, 2015. 
[18] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. 
[19] I. Sutskever, J. Martens, G. Dahl, and G. Hinton. On the importance of initialization and momentum in deep learning. In Proceedings of the 30th International Conference on Machine Learning (ICML-13), volume 28, pages 1139â€“1147. JMLR Workshop and Conference Proceedings, May 2013. 
[20] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1â€“9, 2015. 
[21] T. Tieleman and G. Hinton. Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning, 4, 2012. Accessed: 2015- 11-05. 
[22] A. Toshev and C. Szegedy. Deeppose: Human pose estimation via deep neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 1653â€“1660. IEEE, 2014.
[23] N. Wang and D.-Y. Yeung. Learning a deep compact image representation for visual tracking. In Advances in Neural Information Processing Systems, pages 809â€“817, 2013.